{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNeXt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split, Dataset,  Subset\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"cuda:\", torch.cuda.is_available())\n",
    "\n",
    "# Directory paths in the local machine\n",
    "test_data_path = \"./Dataset/test\"\n",
    "combined_data_path = \"./Dataset/train\"\n",
    "\n",
    "# for reproducibility and quick adjustments\n",
    "torch.manual_seed(0)\n",
    "BATCH_SIZE = 32\n",
    "k_folds = 5\n",
    "num_epochs = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep the training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the Transformations, with data augmentation\n",
    "transform_train = transforms.Compose([\n",
    "    # transforms.RandomResizedCrop(size=224, scale=(0.5, 1.0), ratio=(0.75, 1.33), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    # transforms.RandomAffine(degrees=5, translate=(0.05, 0.05), scale=(0.95, 1.05)),\n",
    "    # transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.Resize((224, 224), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# for validation without data augmentation\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create a dataset with training transform\n",
    "full_dataset = datasets.ImageFolder(root=combined_data_path, transform=transform_train)\n",
    "\n",
    "# Create a KFold object with k_folds number of splits\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "# # Split the dataset into train and validation sets\n",
    "# num_train = len(full_dataset)\n",
    "# num_val = int(0.2 * num_train)\n",
    "# num_train -= num_val\n",
    "# train_subset, val_subset = random_split(full_dataset, [num_train, num_val])\n",
    "\n",
    "# # Manually set the transform for validation subset\n",
    "# val_subset.dataset.transform = transform_val\n",
    "\n",
    "# # Create DataLoaders for training and validation sets\n",
    "# train_loader = DataLoader(dataset=train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# val_loader = DataLoader(dataset=val_subset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# # Display training/validation set count\n",
    "# print(f\"Training image count: {len(train_subset)}\")\n",
    "# print(f\"Validation image count: {len(val_subset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For the test set, since there are no labels, we need to create a custom DataSet.\n",
    "# class UnlabeledDataset(datasets.VisionDataset):\n",
    "#     def __init__(self, root_dir, transform=None):\n",
    "#         super(UnlabeledDataset, self).__init__(root_dir, transform=transform)\n",
    "#         self.images = [os.path.join(root_dir, img) for img in os.listdir(root_dir)]\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         image_path = self.images[index]\n",
    "#         image = datasets.folder.default_loader(image_path)  # default loader is PIL.Image.open\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "#         return image, str(image_path)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.images)\n",
    "\n",
    "# Custom dataset loader to handle unlabeled data.\n",
    "class UnlabeledDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_list = os.listdir(root_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.image_list[idx])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.image_list[idx]\n",
    "\n",
    "test_dataset = UnlabeledDataset(root_dir=test_data_path, transform=transform_val)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Model with ResNeXt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnext = models.resnext50_32x4d(pretrained=True)\n",
    "resnext = models.resnext101_32x8d(pretrained=True)\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, resnext):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.resnext = resnext\n",
    "        num_features = resnext.fc.in_features  # Get the number of inputs for the last layer\n",
    "        self.resnext.fc = nn.Identity() # Repace the last fc layer with a place holder\n",
    "\n",
    "        # Freeze all pretrained layers\n",
    "        for param in self.resnext.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),  # 50% of the neurons are dropped out\n",
    "            nn.Linear(num_features, 100)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnext(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# model = MyModel(resnext)\n",
    "# model = model.to(device)\n",
    "\n",
    "# # Load a pre-trained ResNeXt model (or resnext101_32x8d)\n",
    "# model = models.resnext50_32x4d(pretrained=True)\n",
    "# # model = models.resnext101_32x8d(pretrained=True)\n",
    "\n",
    "# # Replace the last fully connected layer\n",
    "# num_features = model.fc.in_features  # Get the number of inputs for the last layer\n",
    "# model.fc = nn.Sequential(\n",
    "#     nn.Dropout(0.5),  # 50% of the neurons are dropped out\n",
    "#     nn.Linear(num_features, 100)\n",
    "# )\n",
    "\n",
    "# # Freeze all layers\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# # Unfreeze the last layer\n",
    "# for param in model.fc.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "# # # Unfreeze additional layers\n",
    "# # for name, child in model.named_children():\n",
    "# #     if name in ['layer4']:  # Unfreeze 'layer4'\n",
    "# #         for param in child.parameters():\n",
    "# #             param.requires_grad = True\n",
    "\n",
    "# model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# # Define the optimizer\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-2) # weight_decay is L2 regularization\n",
    "# # optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of training loss and validation accuracy\n",
    "all_train_losses = [[] for _ in range(num_epochs)]\n",
    "all_val_accuracies = [[] for _ in range(num_epochs)]\n",
    "\n",
    "# num_epochs = 1  # debug\n",
    "\n",
    "# Start the k-fold cross-validation\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(full_dataset)):\n",
    "    print(f'Starting fold {fold+1}/{k_folds}')\n",
    "    train_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    #initiate model\n",
    "    model = MyModel(resnext)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-2) # weight_decay is L2 regularization\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Split the dataset into training and validation subsets for the current fold\n",
    "    train_subset = Subset(full_dataset, train_ids)\n",
    "    val_subset = Subset(full_dataset, val_ids)\n",
    "\n",
    "    # Manually set the transform for validation subset\n",
    "    val_subset.dataset.transform = transform_val\n",
    "\n",
    "    # Create data loaders for the current fold\n",
    "    train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # Training and validation loop for the current fold\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training loop\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        total_val_accuracy = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_val_accuracy += (predicted == labels).sum().item()\n",
    "\n",
    "        # Calculate average loss and accuracy for the current epoch\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        avg_val_accuracy = total_val_accuracy / len(val_loader.dataset)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_accuracies.append(avg_val_accuracy)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Fold [{fold+1}/{k_folds}], Loss: {avg_train_loss:.4f}, Validation Accuracy: {avg_val_accuracy:.2f}%')\n",
    "\n",
    "    # Aggregate metrics across folds\n",
    "    for i in range(num_epochs):\n",
    "        all_train_losses[i].append(train_losses[i])\n",
    "        all_val_accuracies[i].append(val_accuracies[i])\n",
    "    # End of the fold\n",
    "    print(f'Fold {fold+1} completed.\\n')\n",
    "    \n",
    "# Calculate the average metrics across all folds\n",
    "avg_train_losses = [np.mean(losses) for losses in all_train_losses]\n",
    "avg_val_accuracies = [np.mean(acc) for acc in all_val_accuracies]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Training Loss and Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the averaged training loss and validation accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_epochs + 1), avg_train_losses, label='Average Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Across Folds')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_epochs + 1), avg_val_accuracies, label='Average Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Validation Accuracy Across Folds')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "\n",
    "# # Plot training loss\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(train_losses, label='Training Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Training Loss')\n",
    "# plt.legend()\n",
    "\n",
    "# # Plot validation accuracy\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Validation Accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eva;uate and create the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model's evaluation mode\n",
    "model.eval()\n",
    "\n",
    "test_predictions = []\n",
    "\n",
    "# Assuming the model is already in evaluation mode and device is defined\n",
    "with torch.no_grad():\n",
    "    for images, paths in tqdm(test_loader, desc='Predicting labels'):\n",
    "        images = images.to(device)\n",
    "\n",
    "        # Get predictions\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predicted_labels = [full_dataset.classes[p] for p in predicted.cpu().numpy()]\n",
    "\n",
    "        # Go through the batch and add to our prediction list, including image paths\n",
    "        for path, label in zip(paths, predicted_labels):\n",
    "            test_predictions.append((Path(path).name, label))  # Appending a tuple of filename and label\n",
    "\n",
    "with open('./CSV Files/submission_kfold.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['ID', 'Label'])\n",
    "    writer.writerows(test_predictions)  # Writing all predictions at once"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
