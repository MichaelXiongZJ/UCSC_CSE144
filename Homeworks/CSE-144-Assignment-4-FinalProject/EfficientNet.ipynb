{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Michael/.cache\\torch\\hub\\facebookresearch_swag_main\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split, Dataset\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "%matplotlib inline\n",
    "\n",
    "# Data Augmentation for the training dataset\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "    transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Transformation for the validation dataset\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load and split the dataset\n",
    "combined_data_path = './Dataset/train'\n",
    "full_dataset = datasets.ImageFolder(root=combined_data_path, transform=transform_train)\n",
    "num_train = len(full_dataset)\n",
    "num_val = int(0.2 * num_train)\n",
    "train_subset, val_subset = random_split(full_dataset, [num_train - num_val, num_val])\n",
    "val_subset.dataset.transform = transform_val  # Apply validation transformation\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Model, Loss, and Optimizer\n",
    "# vit_l32 = models.vit_l_32(pretrained=True)\n",
    "# vit_h14 = models.vit_h_14(pretrained=True)\n",
    "# vit_l16 = models.vit_l_16(pretrained=True)\n",
    "vit_l16 = torch.hub.load(\"facebookresearch/swag\", model=\"vit_l16\")\n",
    "\n",
    "class ModifiedViT(nn.Module):\n",
    "    def __init__(self, pretrained_model):\n",
    "        super(ModifiedViT, self).__init__()\n",
    "        self.pretrained = pretrained_model\n",
    "        self.pretrained.head = nn.Identity()  # Remove the existing linear layer\n",
    "\n",
    "        # Freeze all pretrained layers\n",
    "        for param in self.pretrained.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Assuming the attribute is named 'hidden_size'\n",
    "        # num_feature = self.pretrained.  # Replace with the correct attribute\n",
    "        self.new_head = nn.Sequential(\n",
    "            nn.Linear(1024, 100),  # Adjust the input size to match the output size of the ViT model\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pretrained(x)\n",
    "        x = self.new_head(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Create the modified model\n",
    "model = ModifiedViT(vit_l16)\n",
    "\n",
    "# Move to the appropriate device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.new_head.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
    "\n",
    "# Training with dynamic data augmentation\n",
    "num_epochs = 30\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_losses.append(total_loss / len(train_loader))\n",
    "    train_accuracies.append(100 * correct / total)\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_accuracies.append(100 * correct / total)\n",
    "    scheduler.step(total_loss / len(train_loader))\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_losses[-1]:.4f}, Training Accuracy: {train_accuracies[-1]:.2f}%, Validation Accuracy: {val_accuracies[-1]:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot for training loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot for training and validation accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset loader to handle unlabeled data.\n",
    "class UnlabeledDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_list = os.listdir(root_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.image_list[idx])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.image_list[idx]\n",
    "\n",
    "test_dataset = UnlabeledDataset(root_dir='./dataset/test', transform=transform_val)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "# Model's evaluation mode\n",
    "model.eval()\n",
    "\n",
    "test_predictions = []\n",
    "\n",
    "# Assuming the model is already in evaluation mode and device is defined\n",
    "with torch.no_grad():\n",
    "    for images, paths in tqdm(test_loader, desc='Predicting labels'):\n",
    "        images = images.to(device)\n",
    "\n",
    "        # Get predictions\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predicted_labels = [full_dataset.classes[p] for p in predicted.cpu().numpy()]\n",
    "\n",
    "        # Go through the batch and add to our prediction list, including image paths\n",
    "        for path, label in zip(paths, predicted_labels):\n",
    "            test_predictions.append((Path(path).name, label))  # Appending a tuple of filename and label\n",
    "\n",
    "with open('./CSV Files/submission_efficientNet.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['ID', 'Label'])\n",
    "    writer.writerows(test_predictions)  # Writing all predictions at once"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
