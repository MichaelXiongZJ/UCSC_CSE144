{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CJ4TWF8biDE"
      },
      "source": [
        "# CSE144 Code Exercise SENet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxAxJtJUbiDH"
      },
      "source": [
        "This example implements the [Squeeze-and-Excitation Networks (SENet)](https://arxiv.org/abs/1709.01507)\n",
        "model for image classification,\n",
        "and demonstrates it on the CIFAR-100 dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ksuu0JhbiDH"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-1FPLlJDbiDI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda availability: False\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import CIFAR100\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"cuda availability:\", torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RagvbG5c2W_Y"
      },
      "source": [
        "## Configure the hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDDWWqzQ2VJQ"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "batch_size = 256\n",
        "image_size = 32 # Updated image size\n",
        "image_channels = 3\n",
        "num_epochs = 10 # short training for demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IMGSH-6biDJ"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2J6RWgHbiDJ",
        "outputId": "e3a4aaa8-4ad8-4a9d-babc-be6312b513d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 169001437/169001437 [00:01<00:00, 104958761.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "# Prepare the data\n",
        "num_classes = 100\n",
        "# input_shape = (32, 32, 3)\n",
        "\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size)),  # Resize to 72x72\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(degrees=7),\n",
        "    # transforms.RandomResizedCrop(size=image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size)),  # Resize to 72x72\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276])\n",
        "])\n",
        "\n",
        "train_dataset = CIFAR100(root=\"./data\", train=True, transform=train_transform, download=True)\n",
        "test_dataset = CIFAR100(root=\"./data\", train=False, transform=test_transform, download=True)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qaHXTQyNrcr"
      },
      "source": [
        "## Define SE Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_UnPWps_Jn1"
      },
      "outputs": [],
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "class SELayer(nn.Module):\n",
        "    def __init__(self, channel, reduction=16):\n",
        "        super(SELayer, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, channel, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y.expand_as(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6r2HXZ2fNrj1"
      },
      "outputs": [],
      "source": [
        "class CifarSEBasicBlock(nn.Module):\n",
        "    def __init__(self, inplanes, planes, stride=1, reduction=16):\n",
        "        super(CifarSEBasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.se = SELayer(planes, reduction)\n",
        "        if inplanes != planes:\n",
        "            self.downsample = nn.Sequential(nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False),\n",
        "                                            nn.BatchNorm2d(planes))\n",
        "        else:\n",
        "            self.downsample = lambda x: x\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.downsample(x)\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.se(out)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnMU-adkNr1C"
      },
      "source": [
        "## Define SE ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeenYYjXNr9U"
      },
      "outputs": [],
      "source": [
        "class CifarSEResNet(nn.Module):\n",
        "    def __init__(self, block, n_size, num_classes=10, reduction=16):\n",
        "        super(CifarSEResNet, self).__init__()\n",
        "        self.inplane = 16\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            3, self.inplane, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.inplane)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self._make_layer(\n",
        "            block, 16, blocks=n_size, stride=1, reduction=reduction)\n",
        "        self.layer2 = self._make_layer(\n",
        "            block, 32, blocks=n_size, stride=2, reduction=reduction)\n",
        "        self.layer3 = self._make_layer(\n",
        "            block, 64, blocks=n_size, stride=2, reduction=reduction)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Linear(64, num_classes)\n",
        "        self.initialize()\n",
        "\n",
        "    def initialize(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride, reduction):\n",
        "        strides = [stride] + [1] * (blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.inplane, planes, stride, reduction))\n",
        "            self.inplane = planes\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_PMWhbPOVb6"
      },
      "outputs": [],
      "source": [
        "def se_resnet20(num_classes=10):\n",
        "    model = CifarSEResNet(CifarSEBasicBlock, 3, num_classes=num_classes)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvm9TSjybiDO"
      },
      "source": [
        "## Compile, train, and evaluate the mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hA1WKEknbiDO",
        "outputId": "7acecb9f-b18b-40fc-9c8e-336c8b58d9db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Test Accuracy: 13.28%\n",
            "Epoch [2/10], Test Accuracy: 20.35%\n",
            "Epoch [3/10], Test Accuracy: 25.38%\n",
            "Epoch [4/10], Test Accuracy: 27.92%\n",
            "Epoch [5/10], Test Accuracy: 30.30%\n",
            "Epoch [6/10], Test Accuracy: 33.36%\n",
            "Epoch [7/10], Test Accuracy: 35.35%\n",
            "Epoch [8/10], Test Accuracy: 37.92%\n",
            "Epoch [9/10], Test Accuracy: 37.28%\n",
            "Epoch [10/10], Test Accuracy: 39.16%\n"
          ]
        }
      ],
      "source": [
        "# Create and train the PyTorch model\n",
        "\n",
        "def run_experiment(model, train_loader, test_loader, num_epochs=10, learning_rate=0.001, weight_decay=0.0001):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    model = model.to(device)\n",
        "    criterion = criterion.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = correct / total\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Test Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "model = se_resnet20(num_classes=100)\n",
        "run_experiment(model, train_loader, test_loader, num_epochs=num_epochs, learning_rate=learning_rate, weight_decay=weight_decay)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
